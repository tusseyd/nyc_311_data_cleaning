\documentclass[linenumber]{jdsart}
\pdfminorversion=7

\usepackage{siunitx}
\sisetup{
    group-separator = {,},
    round-mode = places,
    round-precision = 2,
    output-decimal-marker = {.},
    table-number-alignment = center,
    table-figures-integer = 6,
    table-figures-decimal = 2,
    table-figures-uncertainty = 2
}

\usepackage{comment}
\usepackage{multicol}
%\usepackage{fontawesome5}
%\usepackage{booktabs, textgreek}
\usepackage{booktabs}  % for \toprule, \midrule, \bottomrule
\usepackage{threeparttable}  % for table notes
\usepackage{rotating}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{dirtree}
\usepackage{tikz}
\usetikzlibrary{positioning}

% image path
\graphicspath{{./}{./supplemental_images/}}

% =========================================================
% AUTO SUPPLEMENT NUMBERING (Tables/Figures as S1, S2, ...)
% =========================================================
\makeatletter
\renewcommand{\thefigure}{S\arabic{figure}}   % Figures: S1, S2, S3...
\renewcommand{\thetable}{T\arabic{table}}     % Tables: T1, T2, T3...
\renewcommand{\fnum@table}{\tablename~\thetable}
\renewcommand{\fnum@figure}{\figurename~\thefigure}
\makeatother

%% float control
\renewcommand\floatpagefraction{0.75}
\setcounter{totalnumber}{50}
\setcounter{topnumber}{50}
\setcounter{bottomnumber}{50}

% hyperref settings (safe to keep)
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

\hyphenpenalty=950

\volume{0}
\issue{0}
\pubyear{2025}
\doi{0000}


\usepackage{xcolor}
\newcommand{\dt}[1]{\textcolor{purple}{DT: (#1)}}
\newcommand{\jy}[1]{\textcolor{red}{JY: (#1)}}

\begin{document}

\begin{frontmatter}

\title{\Large Supplementary Materials for:}
\subtitle{\large Principles for Open Data Curation: A Case Study with the New York City 311 Service Request Data\\[2ex]}

\author[1]{\inits{D.}\fnms{David}~\snm{Tussey}}
\author[2]{\inits{J.}\fnms{Jun}~\snm{Yan}}

\runtitle{Supplementary Materials: NYC 311 Data Cleansing}
\runauthor{Tussey and Yan}

\address[1]{\institution{NYC Department of Information Technology and Telecommunications}, \cny{USA}}
\address[2]{Department of Statistics, \institution{University of Connecticut}, \cny{USA}}

\begin{keywords}
\kwd{Data cleansing}
\kwd{Data quality}
\kwd{Data science}
\kwd{Data Validation}
\kwd{NYC Open Data}
\end{keywords}

\end{frontmatter}

% Table of contents and lists
%\tableofcontents
%\listoffigures
%\listoftables
%\newpage


%---------------------------------------------------------------
\section{Overview}

This document provides supplementary materials accompanying the article
\emph{Principles for Open Data Curation: A Case Study with the New York City 
311 Service Request Data}. It includes additional figures, tables, extended 
methodological details,  selected console output, and reproducibility 
information that support—but are not included in—the main document.
The supplementary materials are intended to improve transparency,
facilitate reproducibility, and provide additional technical context
for readers interested in the data-cleaning and validation processes
applied in this study.


The below examples represent typical charts and tables created by the 
R programs. A full listing of the tables produced is available in the 
\emph{reference} named text files stored on GitHub. The charts shown below are
representative of the types of anomalies discovered and the associated
Pareto and box plot visualizations. A full listing of the tables produced 
is available in the reference console output files stored on GitHub. 
The charts shown are representative of the types of anomalies 
discovered and the associated Pareto, bar, violin, and box plot visualizations.


\begin{itemize}
\item Data preparation: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/console_output/reference_JDS_data_prep_console_output.txt}
\vspace{0.1cm}
\item Data cleaning: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/console_output/reference_JDS_datacleaning_console_output.txt}
\end{itemize}
\jy{The urls are not correct.}

\jy{Avoid manual spacing control}



%---------------------------------------------------------------
\section{Anomaly Detection: Visualizations, Statistics, and Analysis}


This section presents illustrative examples of the visualizations and analytical 
approaches employed throughout the data cleansing program. While the full analysis 
generates dozens of charts across multiple data quality dimensions, the examples 
below demonstrate both the visualizations and the interpretive framework 
applied to identify and characterize data quality issues.

The analysis relies heavily on Pareto charts that stratify quality metrics and 
anomalies---such as invalid \texttt{community\_board} values or suspicious 
durations---by NYC agency. As such, these charts serve a diagnostic purpose: 
they identify whether an anomaly concentrates within a few agencies or a 
single agency, suggesting an agency-specific data entry error or system 
configuration issue and thus affording targeted correction. Second, 
they reveal whether anomalies distribute proportionally across Agencies 
mirroring the overall 311 Service Request (SR) volume distribution, 
indicating a systemic problem affecting the entire dataset rather than 
isolated to particular agencies.

Beyond Pareto charts, the program generates complementary visualizations including 
box plots (revealing distributional characteristics and outliers), violin plots 
(showing probability density across agencies), and histograms (exposing temporal 
or magnitude patterns). Each chart type supports specific analytical 
questions about data quality. The examples below illustrate how these chart types 
combine to enable comprehensive data quality assessment and inform targeted 
remediation strategies.


\subsection{Service Request Status (SR) and Closure Analysis}


Figure~\ref{fig:pareto-closed-status-missing-date}, shows a classic 
example of identifying the source agency associated with an anomaly. 
In this case, the anomaly is an SR that has a \texttt{status}
of \textit{closed}, but is missing the \texttt{closed\_date} entry. The Pareto chart 
reveals that this is a problem located almost exclusively within the NYC
Department of Homeless Services (DHS), where 99.7\% such anomalies occur.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{pareto_closed_status_missing_closed_date_by_agency.pdf}
\caption{Pareto chart of SRs with a CLOSED status, but missing \texttt{closed\_date}, by Agency.}
\label{fig:pareto-closed-status-missing-date}
\end{figure}


Conversely, Figure~\ref{fig:pareto-nonclosed-with-date} displays the anomaly of having 
a \texttt{closed\_date}, but \emph{not} having a \texttt{status} of CLOSED. This anomaly 
is shown to primarily exist within the Department of Transportation (DOT) representing
a full 77\%, with smaller, yet significant, anomalies occurring within the Department of
Buildings (DOB) and the Department of Sanitation (DSNY).


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{pareto_nonclosed_status_with_closed_date_by_agency.pdf}
\caption{Pareto chart of SRs with NOT-CLOSED status, but has a \texttt{closed\_date}, by Agency.}
\label{fig:pareto-nonclosed-with-date}
\end{figure}


\subsection{Temporal Pattern Analysis}


The charts can also reveal trends in an anomaly. As noted in the reference document,
there is a pronounced spike in the number of SRs closed \emph{exactly} at 
midnight (00:00:00). This spike potentially indicates a automated bulk-action 
software program that appears to close selected SRs exactly at midnight. Note, however, 
that as shown in Figure~\ref{fig:closed-exact-midnight-cy} the yearly 
distribution of midnight \texttt{closed\_date)}(s) appears to be decreasing in 
the more current years. 


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{closed_exact_midnight_cy_distribution.pdf}
\caption{Calendar year distribution of SRs with a midnight \texttt{closed\_date}.}
\label{fig:closed-exact-midnight-cy}
\end{figure}


Supplementing that discovery is Figure~\ref{fig:pareto-closed-midnight}, a 
Pareto chart of the midnight  closing anomaly by agency. The chart shows that 
the majority of the SRs closed-at-midnight occur within just two Agencies, DSNY 
and DOB, which collectively are responsible for 97.6\% of such anomalies. Such
information reveals a point-of-action for further investigation.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{pareto_closed_exact_midnight_agency.pdf}
\caption{Pareto chart of SRs with a midnight \texttt{closed\_date}, by Agency.}
\label{fig:pareto-closed-midnight}
\end{figure}


\subsection{Service Request (SR) Positive Duration Analysis}

One anomaly discussed in the referenced document is the presence of unusually long time spans 
between an SR being opened and when it is closed, referred to as the duration or response time. 
Such durations are frequently used to measure the performance of an agency's customer service. 
The following is an extended analysis of this long duration phenomenon that reveals not only 
the value of various visualizations, but also demonstrates the methodological approach to an 
underlying issue---a textbook study of Simpson's paradox where aggregate data distorts 
or conceals the underlying details.


In Figure~\ref{fig:boxplot-large-positive-durations} the box plot shows durations 
calculated as $\texttt{closed\_date} - \texttt{created\_date}$. The anomaly 
measured is SRs that have large positive durations, for this box plot 
between two and five years (730--1825 days) --- duration limits that 
seem reasonable to count as \emph{large} This chosen range also excludes 1240 extreme durations,
many of which appear to be caused by data entry errors, such as a 
\texttt{created\_date} of 1900-01-01. There are 139{,}628 such \emph{large}
durations SRs. As shown in Figure~\ref{fig:boxplot-large-positive-durations}, the box 
plot shows that the Department of Parks and Recreation (DPR) is responsible 
for most of these large durations, followed closely by the Department
of Health and Mental Hygiene (DOHMH), the Economic Development 
Council (EDC) and DSNY. 


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{boxplot_large_positive_days_by_agency.pdf}
\caption{Distribution of SRs with Large Positive durations (730--1{,}82 days), by Agency.}
\label{fig:boxplot-large-positive-durations}
\end{figure}


Not only do these four Agencies contribute
significantly to the long-duration SR metric, but the statistical mean of such 
durations, and the spread are also quite high. Meanwhile, as 
Figure~\ref{fig:boxplot-large-positive-durations} reveals, 
the NYPD, has a large number of large duration SRs, but relatively small such durations 
limited in magnitude with the mean duration being just over the 
two year lower limit at 771 days and a tight $\sigma$ of 79. Other agency's
$\sigma$ values are 2-4X that magnitude, indicating a broader spread. All 
agency values can be obtained by observing the associated 
box plot chart, supplemented by two tables produced in the 
console output \texttt{.tex} file.


Further insight emerges from analyzing \emph{all} SRs with positive 
durations, regardless of magnitude---15.3 million observations comprising 
94\% of the dataset. Figure~\ref{fig:histogram_city_wide} presents a histogram 
of these durations on a logarithmic scale, revealing an bimodal distribution. Hartigan's 
dip test confirms this bimodality is statistically significant 
($D = 0.027$, $p < 2.2 \times 10^{-16}$),  a near-zero p value that 
decisively rejects the null hypothesis of unimodality. Indeed visual
inspection of Figure~\ref{fig:bimodal_hist} confirms that; indeed there is 
a distinct bimodal distribution, which would seem to require 
further analysis. Also of note is the separation of the median from the
mean, indicating a skewed distribution to the right (Bowley skewness = 0.8079).
Note also the large spread between the median (0.44 days) and the mean (23.72 days)
further indicating the presence of outliers to the right.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{All-Agencies histogram_positive_durations.pdf}
\caption{SR Distribution with Positive Durations: All Agencies (log scale).}
\label{fig:histogram_city_wide}
\end{figure}


In order to objectively identify the separation threshold between the two modes, 
the kernel density estimation method is employed. Using log-transformed durations
the kernel density method located the local minimum between the two 
peaks. This valley-based approach yielded a threshold of 0.432 days (10.4 hours), 
which provides a criterion for classifying service requests into two different operational
categories: \emph{rapid-resolution} ($< 0.432$ days duration) and 
\emph{standard} work orders ($\geq 0.432$ days duration).


Table~\ref{tab:mode_summary} presents summary statistics for each operational mode, 
standard and rapid-resolution. Based on the separation threshold of 0.432 days, 
the rapid-resolution mode comprises 49.9\% of requests (n = 7.66M) with a 
median duration of 0.87 hours and mean of 1.72 hours. The standard 
mode accounts for 50.1\% of requests (n = 7.69M) with a median of 101.1 hours 
and mean of 1135 hours days. This near-perfect 50/50 split masks dramatically different
operational models across city agencies---a clear example of Simpson's Paradox, 
where aggregate statistics obscure the true underlying structure when 
different, distinct populations are inappropriately combined. 


% Table 1: Summary statistics by operational mode
\begin{table}[htbp]
\centering
\caption{Summary Statistics by Operational Mode}
\label{tab:mode_summary}
\begin{tabular}{lrrrrrr}
\toprule
Mode & N & \% & Median & Mean & 95th \%ile \\
 & & & (days) & (days) & (days) \\
\midrule
Rapid-resolution & 7,663,869 & 49.9 & 0.036 & 0.072 & 0.28 \\
Standard & 7,689,398 & 50.1 & 4.2 & 47.3 & 211.0 \\
\midrule
Total & 15,353,267 & 100.0 & 51.6 & 569.0 & --- \\
\bottomrule
\end{tabular}
\end{table}


Table~\ref{tab:agency_mode} provides a further breakout of durations by 
agency. It reveals that NYPD dominates the rapid-resolution mode, 
accounting for 87\% of all fast closures (6.69M out of 7.66M requests). 
Critically, 96.8\% of NYPD's SRs close within 10.2 hours (0.43 days) --- based
on the bimodal threshold of 0.432 days --- reflecting rapid 
responses to quality-of-life complaints. In stark contrast, 
infrastructure and regulatory agencies operate primarily in standard 
mode: HPD (96.1\% standard), DSNY (92.9\% standard), DOB (91.1\% standard), 
and DPR (90.1\% standard). It seems reasonable to assume that 
the nature of the SRs for these agencies require more physical 
service delivery, construction permits, code enforcement, or 
ongoing case investigation, thus potentially creating longer SR durartions. 


% Table 2: Agency distribution across operational modes
\begin{table}[htbp]
\centering
\caption{Distribution of Service Requests Across Operational Modes by Agency}
\label{tab:agency_mode}
\begin{tabular}{lrrrrr}
\toprule
& \multicolumn{2}{c}{Rapid-resolution} & \multicolumn{2}{c}{Standard} & \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
Agency & N & \% & N & \% & Total N \\
\midrule
NYPD & 6,685,153 & 96.8 & 220,228 & 3.2 & 6,905,381 \\
DSNY & 134,259 & 7.1 & 1,764,460 & 92.9 & 1,898,719 \\
HPD & 119,439 & 3.9 & 2,934,707 & 96.1 & 3,054,146 \\
DOT & 179,113 & 19.7 & 728,215 & 80.3 & 907,328 \\
DEP & 269,193 & 34.8 & 504,885 & 65.2 & 774,078 \\
DPR & 56,294 & 9.9 & 511,518 & 90.1 & 567,812 \\
DOB & 36,295 & 8.9 & 372,975 & 91.1 & 409,270 \\
DOHMH & 28,816 & 12.5 & 201,532 & 87.5 & 230,348 \\
DHS & 104,170 & 64.1 & 58,468 & 35.9 & 162,638 \\
EDC & 3,968 & 3.0 & 126,227 & 97.0 & 130,195 \\
DCWP & 2,373 & 2.0 & 113,744 & 98.0 & 116,117 \\
TLC & 10,119 & 8.6 & 106,997 & 91.4 & 117,116 \\
\midrule
All agencies & 7,663,281 & 49.9 & 7,689,986 & 50.1 & 15,353,267 \\
\bottomrule
\end{tabular}
\end{table}


Identifying this bimodal structure has significant implications 
for data quality assessment and performance measurement. It 
means that the overall aggregate mean duration of 23.7 days 
is a misleading summary statistic---it falls in between the 
two operational modes and represents neither reality. 
Performance metrics, anomaly detection thresholds, and 
quality benchmarks must account for this operational difference 
to avoid spurious findings and invalid cross-agency comparisons.


Three key conclusions emerge from this analysis: (1) the overall 
SR duration distribution is inaccurate and conceals two distinctly 
different operational modes---rapid-response and standard work-order 
processing; (2) NYPD is responsible for the vast majority of 
rapid-response durations; and (3) all other agencies combined 
constitute the vast majority of standard durations. A deeper can help
discover the underling, distinct distributions. Visualizing how the 
durations of these two operational modes requires separating the 
durations of the NYPD versus all other Agencies. 
Figure~\ref{fig:histogram_NYPD} show NYPD-only positive 
distributions. Of note is that the median and mean lines are separated, 
indicating a right skewness possibly driven by a small number of large 
durations which have an outsized effect on the mean statistic.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{nypd_only_positive_durations.pdf}
\caption{Distribution of SRs with Positive Durations: NYPD-only (log scale).}
\label{fig:histogram_NYPD}
\end{figure}


In contrast to the NYPD-only durations is the aggregation of all other NYC 
Agencies, as shown in Figure~\ref{fig:histogram_other}, reveals a broader 
range of durations, with an exceptional number of very large, almost extreme,
durations in the \textgreater{}1000 days (note that the x-axis is a 
logarithmic scale). 

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{others_only_positive_durations.pdf}
\caption{Distribution of SRs with Positive Durations: All non-NYPD Agencies (log scale).}
\label{fig:histogram_other}
\end{figure}


A clearer picture emerges as the two distributions (NYPD vs. all other Agencies) are 
superimposed on the same chart. Figure`\ref{fig:histogram_combined} clearly shows
the bimodal distribution, reflecting the distinctly different operational 
protocols for the two categories --- rapid-response and standard. 
Keep in mind that the NYPD is the single largest user of the 
NYC 311 non-emergency service, representing 43\% of all SRs. 
Thus, so it is perhaps not unusual to see that one agency 
have an outsized impact on the overall metric.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{nypd_vs_others_combined.pdf}
\caption{Combined Duration Profiels: NYPD and all other Agencies (log scale).}
\label{fig:histogram_combined}
\end{figure}


\subsection{Service Request Negative Duration Analysis}


A similar situation is illustrated in Figure~\ref{fig:boxplot-negative-durations} 
showing negative durations --- where the \texttt{closed\_date} occurs before 
the \texttt{created\_date} resulting in a nonsensical negative duration. 
In Figure~\ref{fig:boxplot-negative-durations} , the box plot 
shows DOT to be the largest offender. However, the mean 
negative duration is far greater for the Department of Environmental 
Protection (DEP) as shown on a logarithmic x-axis. This box plot visualization 
captures both the count and the extent of the negative duration anomaly.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{boxplot_negative_days_by_agency.pdf}
\caption{Distribution of negative durations (closed $<$ created date) by agency)}
\label{fig:boxplot-negative-durations}
\end{figure}


Violin charts of these same distributions are also produced and 
available in the \texttt{charts} directory upon completion of the 
data cleansing program. Figure ~\ref{fig:violin-boxplot-negative}
displays a violin chart that accompanies the negative duration 
box plot, revealing the density of negative durations by magnitude. 
Every box plot has an accompanying violin chart.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{violin_boxplot_negative_days_by_agency.pdf}
\caption{Combined violin and boxplot for SRs with negative durations, by Agency.}
\label{fig:violin-boxplot-negative}
\end{figure}


\subsection{Zero and Near-Zero/Suspicious Duration Analysis}


One challenging area was determining which duration values are 
impossible, improbable, or suspicious. Some duration categories are 
obvious, such as zero-second durations where the \texttt{created\_date} 
and \texttt{closed\_date} are identical, to the second. Indeed, there 
are 387{,}329 such impossible-duration SRs. Additionally, there 
are 3{,}460 SRs with a duration of exactly one second, a highly 
improbable if not impossible duration. Finally, there are SRs 
with quite small durations, e.g., just a few seconds, which are highly 
suspicious. These are classified as near-zero durations or suspicious
durations.


The results of this analysis are shown, sorted by the statistical detection 
threshold method, in Figure~\ref{fig:zero-duration-pareto-combo} 
As noted in the referenced document, a quantitative analysis 
revealed a boundary of 28 seconds as an outlier based on the 
(LogNormal\_$3\sigma$) method. Using this value reveals 14$,$741 
suspicious durations. The referenced document also contains rationale
for the use of this outlier methodology.


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{skewed_duration_analysis_methods.pdf}
\caption{Outlier Detection Thresholds by Method. LogNormal\_3SD returned a usable result.}
\label{fig:zero-duration-pareto-combo}
\end{figure}


Figure~\ref{fig:zero-duration-pareto-combo} 
and Figure~\ref{fig:zero-duration-pareto-combo} visualizee the 
this suspicious boundary. These two charts show the overall 
distribution of near-zero duration SRs from 2---90 seconds; one 
showing cumulative and the other showing durations counts. The cumulative 
distribution shows the suspicious threshold of 28 seconds 
representing approximately 12\% of SRs with durations inside that 2---90 
time span. 


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{duration_histogram_cumulative.pdf}
\caption{Cumulative Distribution of SR durations (2--90 seconds).}
\label{fig:zero-duration-pareto-combo}
\end{figure}


\begin{figure}[!htbp]
\centering
\includegraphics[width=0.9\textwidth]{duration_histogram.pdf}
\caption{Distribution of SR durations (2--90 seconds) by count.}
\label{fig:zero-duration-pareto-combo}
\end{figure}


%---------------------------------------------------------------
\subsection{Dataset Field usage by Agency}


A complete field-usage-by-agency matrix is provided as a CSV file, rather 
than due printed to the console, due to its size and dimensionality. 
 Each row in the file corresponds to a single data field, and 
 each column corresponds to an NYC agency. The cell values 
 indicate the count of records in which the given field is 
populated for the specified agency. The final column
contains the total count across all agencies.


Field usage varies substantially by agency, reflecting differences in
operational responsibilities, reporting practices, and data-collection
requirements. Core administrative fields (i. e., \texttt{unique\_key},
\texttt{created\_date}, \texttt{status}. \texttt{agency}, and 
\texttt{complaint\_type}) are fully populated across all 
agencies, whereas location-specific, infrastructure-related, 
and program-specific fields are populated only by agencies for 
which they are operationally relevant. The CSV file is available 
at: \url{https://figshare.com/s/9f878b50687c9e4c540a}


%---------------------------------------------------------------
\section{SR Backlog}


An interesting discovery during this analysis was the volume of 
\emph{backlogged} SRs. An SR is classified as backlogged
if it is open at the end of the calendar year, and thus must be
rolled over and (hopefully) closed during the following year. While 
the total number of SRs grew by 17.5\% from 2020--2024, the 
backlog growth greatly exceeded that rate, increasing by over 
200\% in raw count. Figure~\ref{fig:annual_backlog} 
shows this dramatic growth with backlogged SRs representing 
1.7\% of all SRs entering 2024, as compared to 0.7\% entering 2020.


\begin{figure}[!htbp]
\centering

\includegraphics[width=0.9\textwidth]{annual_backlog_bar_chart.pdf}
\caption{Backlog of SR at the beginning of the Year}
\label{fig:annual_backlog}
\end{figure}


%---------------------------------------------------------------
\section{Reproducibility and Code Access}


\subsection*{System Requirements}


\begin{itemize}
\item R version 4.5.2 or higher (\url{https://cran.r-project.org/})
\item RStudio version 2026.01.0 build 392 or higher (recommended): \\
\url{https://posit.co/download/rstudio-desktop/}
\item Minimum RAM: 16 GB (tested and verified; 32 GB provides faster execution)
\item Disk space: $\sim$15 GB ($\sim$9 GB uncompressed data) + intermediate files + outputs)
\item Operating System: Tested on Windows 10/11; macOS/Linux users will need to 
modify file paths in \texttt{base\_dir}
\end{itemize}


\subsection*{Data and Code Repository}


\begin{itemize}
\item Source code: \url{https://github.com/tusseyd/nyc_311_data_cleaning}
\item NYC 311 dataset (($\sim$1.6 GB zipped, ($\sim$9 GB uncompressed): \\
\url{https://figshare.com/s/e8d479c391edb7224bfa}
\item USPS Zip Codes (4.5 MB): \url{https://figshare.com/s/8aea027d06f4903f2227}
\item Reference console output for validation is available in GitHub repository.
\end{itemize}


\subsection*{Required R Packages}


Both scripts automatically check for and install missing packages. The two R
programs require the following R packages:


\begin{multicols}{4}
\begin{itemize}
    \item data.table
    \item arrow
    \item fasttime
    \item here
    \item zoo
    \item ggpmisc
    \item ggpattern
    \item ggrastr
    \item qcc
    \item qicharts2
    \item grid
    \item gridExtra
    \item sf
    \item stringdist
    \item tidyverse
    \item bslib
    \item shiny
    \item DT
    \item gt
    \item styler
    \item rlang
    \item renv
    \item remotes
    \item moments
    \item diptest
\end{itemize}
\end{multicols}


\subsection*{Analysis Reproduction Overview}


As noted in the \emph{Principles for Open Data Curation: A Case Study with the
New York City 311 Service Request Data} document there are two separate R 
programs which should be executed in order:


\vspace{0.1cm}
\begin{enumerate}[leftmargin=4em]
\item \texttt{data\_prep\_for\_jds\_datacleansing.R} --- Prepares the raw data for analysis
\vspace{0.1cm}
\item \texttt{jds\_datacleansings.R} --- Performs data cleansing and quality assessments
\end{enumerate}
\vspace{0.1cm}
Each of these programs produces a console output file in simple text format, specifically:
\vspace{0.1cm}
\begin{itemize}
\item \texttt{JDS\_data\_prep\_console\_output.txt}
\vspace{0.1cm}
\item \texttt{JDS\_datacleaning\_console\_output.tex}
\end{itemize}
\vspace{0.1cm}
These two files, along with the associated charts provide additional insight 
into the anomalies observed during data cleansing. Upon running 
the \texttt{jds\_datacleansings.R} program, there will be 92 charts in .PDF format in 
the \texttt{charts} directory and a \texttt{field\_usage\_summary\_table.csv}
file in the \texttt{analytics} directory. 


For validation purposes, a reference copy of the two console output files is
available on GitHub. These reference files can also be used to view the full console
output of the two programs, without needing to run the .R programs. Unfortunately,
the full set of 92 charts can only be duplicated by running the 
\texttt{jds\_datacleansings.R} program, as it is not possible to include all charts in either 
the main document nor in this supplementary document. 



\subsection*{Steps for Reproducing the Analysis}
Source files are available at:
\vspace{0.1cm}
\begin{itemize}
  \item \textsc{R} source code (GitHub): \url{https://github.com/tusseyd/nyc_311_data_cleaning}
  \item USPS Zip Code dataset (Figshare): \url{https://figshare.com/s/8aea027d06f4903f2227}
  \item NYC 311 dataset (Figshare): \url{https://figshare.com/s/e8d479c391edb7224bfa}
  \vspace{0.15cm} 
  \item Data preparation console output: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/reference_console_output/reference_JDS_data_prep_console_output.txt}
\vspace{0.15cm}
  \item Data cleaning console output: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/reference_console_output/reference_JDS_datacleaning_console_output.txt}
\end{itemize}
\vspace{0.1cm}
Step 1: Download the two data Files
\vspace{0.1cm}
\begin{enumerate}
\item Download the NYC 311 and USPS Zip Code datasets from Figshare. (links above)
\item Do not rename these files as the scripts expect original filenames:
\vspace{0.1cm}
\begin{itemize}
\item \texttt{5-year\_311SR\_01-01-2020\_thru\_12-31-2024\_AS\_OF\_10-10-2025.zip}
\item \texttt{zip\_code\_database.csv}
\end{itemize}
\vspace{0.1cm}
\item Unzip the zip file ($\sim$9 GB uncompressed) to create a .CSV file. This .CSV 
file should be placed into the raw\_data directory. (See directory structure below.)
\item The zip\_code.csv file should also be placed into the raw\_data directory. Both
of these .CSV files will be modified by the data prep program to the .RDS 
format for ease in processing.
\end{enumerate}
\vspace{0.1 cm}
Step 2: Set Up Project Structure
\begin{enumerate}
\item Clone or download the entire GitHub repository: \\
\url{https://github.com/tusseyd/nyc_311_data_cleaning}
\item Important: Ensure you download all files from the GitHub repo including:
\vspace{0.1 cm}
\begin{itemize}
\item \texttt{code/data\_prep\_for\_jds\_datacleansing.R}
\vspace{0.1 cm}
\item \texttt{code/jds\_datacleansing.R}
\vspace{0.1 cm}
\item All files in \texttt{code/functions/} directory (required dependencies)
\end{itemize}
\vspace{0.1 cm}
\item Running the data preparation program \texttt{data\_prep\_for\_jds\_datacleansing.R} 
will automatically create the following directory structure. The individual files shown 
below will be created by running the data cleansing program. Below is the 
directory structure and the files they will contain after running the data 
cleansing program \texttt{code/jds\_datacleansing.R}. 
\vspace{0.2cm}
\dirtree{%
.1 / (User's R Working Directory).
.2 nyc\_311\_data\_cleaning/ (Project Root).
.3 analytics/.
.4 field\_usage\_summary\_table.csv.
.3 charts/.
.4 [78 PDF files].
.3 code/.
.4 data\_prep\_for\_jds\_datacleansing.R.
.4 jds\_datacleansing.R.
.4 functions/.
.5 [function files].
.3 console\_output/.
.4 JDS\_data\_prep\_console\_output.txt.
.4 JDS\_datacleansing\_console\_output.txt.
.3 data/.
.4 5-year\_311SR\_01-01-2020\_thru\_12-31-2024\_AS\_OF\_10-10-2025.rds.
.4 USPS\_zipcodes.rds.
.4 raw\_data/.
.5 5-year\_311SR\_01-01-2020\_thru\_12-31-2024\_AS\_OF\_10-10-2025.csv.
.5 zip\_code\_database.csv.
.3 reference\_outputs/.
.4 JDS\_data\_prep\_console\_output.txt.
.4 JDS\_datacleansing\_console\_output.txt.
}
\vspace{0.1cm}
Step 3:  Open RStudio and open \texttt{code/data\_prep\_for\_jds\_datacleansing.R}
Modify the \texttt{base\_dir} variable (line 31) to match your local path:
\begin{verbatim}
base_dir <- file.path("your", "path", "here", "nyc_311_data_cleaning")
\end{verbatim}
\textit{Note: Non-Windows users should use forward slashes or 
platform-appropriate path separators}

\vspace{0.1cm}
Step 4: Place the downloaded data files in the following directories:
\vspace{0.1cm}
\begin{itemize}
\item \texttt{5-year\_311SR\_01-01-2020\_thru\_12-31-2024\_AS\_OF\_10-10-2025.csv} $\rightarrow$ \texttt{data/raw\_data/}
\item \texttt{zip\_code\_database.csv} $\rightarrow$ \texttt{data/raw\_data/}
\end{itemize}
\end{enumerate}
\vspace{0.1cm}
Step 5: Run the Data Preparation R program
\begin{enumerate}
\item Execute \texttt{data\_prep\_for\_jds\_datacleansing.R} in RStudio
\item The script will create the directory structure (if missing) and install required R packages.
\item Expected runtime: Approximately 90 minutes on a system with 16 GB 
RAM; ($\sim$30 min on a system with 32 GB RAM \textit{Note: Initial data loading is memory-intensive; the script optimizes 
memory usage after initial processing}
\item Upon completion, verify these files exist:
\vspace{0.1cm}
\begin{itemize}
\item \texttt{data/5-year\_311SR\_01-01-2020\_thru\_12-31-2024\_AS\_OF\_10-10-2025.rds}
\item \texttt{data/USPS\_zipcodes.rds}
\item \texttt{console\_output/JDS\_data\_prep\_console\_output.txt}
\end{itemize}
\end{enumerate}
\vspace{0.1cm}
Step 6: Run the Data Cleansing Analysis R program
\begin{enumerate}
\item Execute \texttt{code/jds\_datacleansing.R} in RStudio
\item Expected runtime: Approximately 60 minutes on a system with 16 GB 
RAM; $\sim$31 minutes on a system with 32 GB.
\item Monitor progress in RStudio's plot pane as charts are generated.
\item The script will produce:

\vspace{0.1cm}
\begin{itemize}
\item 78 PDF charts in \texttt{charts/}
\item \texttt{field\_usage\_summary\_table.csv} in \texttt{data/analytical\_files/}
\item \texttt{console\_output/JDS\_datacleaning\_console\_output.txt}
\end{itemize}
\end{enumerate}


\subsection*{Validation}
Compare your directory structure along with the associated files shown
in the above tree structure. Compare the charts to those in the original document
and in this Supplemental document. Compare your console output files against the 
reference outputs provided in the GitHub repository to verify successful 
reproduction. The console outputs contain many tables of information 
which should match your run. Validation console output files are located at:

\vspace{0.15cm}
\begin{itemize}
\item Data preparation console output: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/reference_console_output/reference_JDS_data_prep_console_output.txt}
\vspace{0.15cm}
  \item Data cleaning console output: \\ \small\url{https://github.com/tusseyd/nyc_311_data_cleaning/blob/main/reference_console_output/reference_JDS_datacleaning_console_output.txt}
\end{itemize}

\subsection*{Notes}
\begin{itemize}
\item Total processing time (data preparation and cleansing): Approximately 2.5 hours 
on a system with 16 GB RAM; $\sim$2X faster on systems with 32 GB.
\item The scripts use \texttt{data.table} for memory-efficient processing of 15+ million records
\item All file paths are configured relative to \texttt{base\_dir} for portability
\item Memory management: Initial data loading requires substantial RAM; the script 
reduces memory footprint after preprocessing.
\end{itemize}


\end{document}
